{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21179,
     "status": "ok",
     "timestamp": 1744378430836,
     "user": {
      "displayName": "Mahdi Ahmadi Kamal",
      "userId": "02908466264960576341"
     },
     "user_tz": -210
    },
    "id": "T0isTRcrx4g4",
    "outputId": "ceb6dcbb-dd7b-491c-db1d-5e142dfdc305"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/48.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/270.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m266.2/270.5 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m270.5/270.5 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q telebot\n",
    "!pip install -q pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 5863,
     "status": "ok",
     "timestamp": 1744378436697,
     "user": {
      "displayName": "Mahdi Ahmadi Kamal",
      "userId": "02908466264960576341"
     },
     "user_tz": -210
    },
    "id": "Lpkr6yIqyPCt"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import pydub\n",
    "import telebot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3305,
     "status": "ok",
     "timestamp": 1744378440595,
     "user": {
      "displayName": "Mahdi Ahmadi Kamal",
      "userId": "02908466264960576341"
     },
     "user_tz": -210
    },
    "id": "jypPbFb5yAcs",
    "outputId": "b99aebc1-8936-4b72-8acd-c2ba485828e6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "mybot = telebot.TeleBot(\"8117558510:AAHC4sNSrozmZC8uCEXIM1BEfMZez1iwWRE\", parse_mode=None)\n",
    "labels = ['Abdollah', 'Azra', 'Davood', 'Javad', 'Khadijeh', 'Kiana', 'Mahdi', 'Maryam', 'Matin', 'Melika', 'Mohadeseh', 'Mohammad', 'Mohammad_parvari', 'Mona', 'Nahid', 'Nima', 'Omid', 'Parisa', 'Parsa', 'Sajedeh', 'Shima', 'Tara']\n",
    "model = tf.keras.models.load_model('/content/drive/MyDrive/Colab_Notebooks/PyLearn7-Assignment59/AudioClassification/weights/audio_classification.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1744378454314,
     "user": {
      "displayName": "Mahdi Ahmadi Kamal",
      "userId": "02908466264960576341"
     },
     "user_tz": -210
    },
    "id": "rQqAwrnGCMhr"
   },
   "outputs": [],
   "source": [
    "os.makedirs(\"voice\")\n",
    "os.makedirs(\"input_audio\")\n",
    "os.makedirs(\"input_audio_chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "19mplGK-yD9Q"
   },
   "outputs": [],
   "source": [
    "@mybot.message_handler(commands=['start'])\n",
    "def send_welcome(message):\n",
    "    msg = mybot.send_message(message.chat.id,\"Hi \"+str(message.chat.first_name) + \"\\n\" +\n",
    "                             \"Welcome to 'pydio classifier bot'\" + \"\\n\" +\n",
    "                             \"If your name is in the list below, this bot can recognize your sound.\" + \"\\n\" +\n",
    "                             \"[Abdollah, Azra, Davood, Javad, Khadijeh, Kiana, Mahdi, Maryam,Matin, Melika, Mohadeseh, Mohammad, Mohammad_parvari, Mona, Nahid,Nima, Omid, Parisa, Parsa, Sajedeh, Shima, Tara]\" + \"\\n\" +\n",
    "                             \"/start_audio_recognition\")\n",
    "\n",
    "\n",
    "@mybot.message_handler(commands=['start_audio_recognition'])\n",
    "def send_audio(message):\n",
    "    msg = mybot.reply_to(message,\"Please send me a few seconds of your voice.\")\n",
    "    mybot.register_next_step_handler(msg,recognize_audio)\n",
    "\n",
    "\n",
    "def audio_preprocess(file_path):\n",
    "    audio = pydub.AudioSegment.from_file(file_path)\n",
    "\n",
    "    audio = audio.set_sample_width(2)    # convert to 16-bit (2 bytes per sample) to avoid tensorflow error\n",
    "    audio = audio.set_frame_rate(48000)\n",
    "    audio = audio.set_channels(1)        # convert stereo audio to mono audio to avoid tensorflow error\n",
    "\n",
    "    chunks = pydub.silence.split_on_silence(audio, min_silence_len=2000, silence_thresh=-45)\n",
    "    result = sum(chunks)\n",
    "    result.export(\"input_audio.wav\", format=\"wav\")\n",
    "\n",
    "    audio = pydub.AudioSegment.from_file(\"input_audio.wav\")\n",
    "    chunks = pydub.utils.make_chunks(audio, 1000)\n",
    "\n",
    "    for i , chunk in enumerate(chunks):\n",
    "        if len(chunk) < 1000 :\n",
    "            continue\n",
    "        chunk.export(os.path.join(\"input_audio_chunks\", f\"voice{i}.wav\"), format=\"wav\")\n",
    "\n",
    "    audio_chunks = []\n",
    "    for audio_chunk in os.listdir(\"input_audio_chunks\"):\n",
    "        audio_chunks.append(audio_chunk)\n",
    "\n",
    "    xs = []\n",
    "    for audio_chunk in audio_chunks:\n",
    "        x = tf.io.read_file(\"input_audio_chunks/\"+audio_chunk)\n",
    "        x, sample_rate = tf.audio.decode_wav(x, desired_channels=1, desired_samples=48000)\n",
    "        x = tf.squeeze(x, axis=-1)\n",
    "        x = x[tf.newaxis,...]\n",
    "        xs.append(x)\n",
    "\n",
    "    return xs\n",
    "\n",
    "\n",
    "def recognize_audio(message):\n",
    "\n",
    "    fileID = message.voice.file_id\n",
    "    file_info = mybot.get_file(fileID)\n",
    "    file_path = file_info.file_path\n",
    "    downloaded_file = mybot.download_file(file_path)\n",
    "\n",
    "    with open(file_path, 'wb') as new_file:\n",
    "        new_file.write(downloaded_file)\n",
    "\n",
    "    xs = audio_preprocess(file_path)\n",
    "\n",
    "    preds = []\n",
    "    for x in xs:\n",
    "        pred = model(x)\n",
    "        label = np.argmax(pred)\n",
    "        preds.append(labels[label])\n",
    "    # print(preds)\n",
    "    most_common = max(set(preds), key=preds.count)                # Finds the most common element in preds list\n",
    "    # print(most)\n",
    "    print(\"The voice belongs to: \", most_common)\n",
    "\n",
    "    mybot.reply_to(message, f'The voice belongs to {most_common}')\n",
    "\n",
    "\n",
    "mybot.infinity_polling()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMtRt+0qW2sjom3b5czP//p",
   "mount_file_id": "1fiGz5eWs0wIuiPGW-cEFbZONXjX6qbsc",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
